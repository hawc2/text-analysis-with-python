{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Batch Topic Modeling Runner\n\nThis notebook provides an easy interface to run topic modeling on large datasets using the batch processing scripts.\n\n**Benefits:**\n- Easy to configure parameters\n- Save configurations for different projects\n- View results directly in the notebook\n- Reproducible analysis\n\n**How to use:**\n1. Edit the configuration in Section 1\n2. **Run Section 2 first** to install all prerequisites (one-time setup)\n3. Run all remaining cells (or Cell â†’ Run All)\n4. View results at the bottom\n\n**First time users:** Make sure to run Section 2 (Install Prerequisites) before running the rest of the notebook!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Configuration\n",
    "\n",
    "Edit these settings for your specific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INPUT DATA CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Choose input type: 'csv', 'directory', or 'directory_with_metadata'\n",
    "INPUT_TYPE = 'directory'  # Change this to match your data format\n",
    "\n",
    "# For CSV input\n",
    "CSV_PATH = 'Data/RottenTomatoes.csv'\n",
    "TEXT_COLUMN = 'content'  # Column name containing text data\n",
    "\n",
    "# For directory input\n",
    "INPUT_DIRECTORY = 'Data/gutenberg-test/clean/'\n",
    "FILE_PATTERN = '*.txt'\n",
    "\n",
    "# For directory with metadata (like Gutenberg dataset)\n",
    "METADATA_CSV = 'Data/gutenberg-test/metadata.csv'\n",
    "PATH_COLUMN = 'local_path'  # Column containing file paths\n",
    "\n",
    "# ============================================================================\n",
    "# OUTPUT CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Output directory (will be created if it doesn't exist)\n",
    "# Using timestamp to avoid overwriting previous results\n",
    "OUTPUT_DIR = f'results/topic_modeling_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "# Or use a fixed name:\n",
    "# OUTPUT_DIR = 'results/my_project_topics'\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Number of topics to extract\n",
    "NUM_TOPICS = 20\n",
    "\n",
    "# Training parameters\n",
    "PASSES = 20  # Number of passes through the corpus (more = better but slower)\n",
    "ITERATIONS = 200  # Maximum iterations\n",
    "CHUNKSIZE = 100  # Documents to process at once (larger = faster but more memory)\n",
    "\n",
    "# Parallel processing (set to number of CPU cores, or 1 for single-threaded)\n",
    "WORKERS = 4\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_STATE = 100\n",
    "\n",
    "# ============================================================================\n",
    "# PREPROCESSING PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Parts of speech to keep (default: NOUN, ADJ, VERB, ADV)\n",
    "ALLOWED_POS = ['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "\n",
    "# Additional stopwords to remove (beyond standard English stopwords)\n",
    "CUSTOM_STOPWORDS = []  # Example: ['movie', 'film', 'said']\n",
    "\n",
    "# Bigram detection parameters\n",
    "MIN_COUNT = 1  # Minimum count for bigrams\n",
    "BIGRAM_THRESHOLD = 100  # Threshold for bigram detection\n",
    "\n",
    "# ============================================================================\n",
    "# ADDITIONAL OPTIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Create visualization (set to False for very large datasets to save time)\n",
    "CREATE_VISUALIZATION = True\n",
    "\n",
    "# Save preprocessed corpus (useful if you want to re-train with different parameters)\n",
    "SAVE_CORPUS = True\n",
    "\n",
    "# Verbose output (more detailed logging)\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Section 2: Install Prerequisites\n\nThis section installs all required packages. **Run this cell first** if you get \"module not found\" errors.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Section 3: Setup and Validation\n\nThis section checks that everything is configured correctly.",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Setup and Validation\n",
    "\n",
    "This section checks that everything is configured correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Section 4: Build Command\n\nThis builds the command to run the batch processing script."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Build Command\n",
    "\n",
    "This builds the command to run the batch processing script."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Section 5: Run Topic Modeling\n\nExecute the batch processing script. This may take several minutes to hours depending on your dataset size."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Run Topic Modeling\n",
    "\n",
    "Execute the batch processing script. This may take several minutes to hours depending on your dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "## Section 6: View Results\n\nLoad and display the topics discovered by the model."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: View Results\n",
    "\n",
    "Load and display the topics discovered by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Section 7: View Visualization\n\nDisplay the interactive pyLDAvis visualization if it was created."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: View Visualization\n",
    "\n",
    "Display the interactive pyLDAvis visualization if it was created."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Section 8: List All Output Files\n\nShow all files generated by the topic modeling process."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: List All Output Files\n",
    "\n",
    "Show all files generated by the topic modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Section 9: Save Configuration (Optional)\n\nSave your configuration for future reference."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Save Configuration (Optional)\n",
    "\n",
    "Save your configuration for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot save configuration - output directory not found\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "config = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'input_type': INPUT_TYPE,\n",
    "    'input_path': str(CSV_PATH if INPUT_TYPE == 'csv' else INPUT_DIRECTORY),\n",
    "    'output_dir': str(OUTPUT_DIR),\n",
    "    'num_topics': NUM_TOPICS,\n",
    "    'passes': PASSES,\n",
    "    'iterations': ITERATIONS,\n",
    "    'chunksize': CHUNKSIZE,\n",
    "    'workers': WORKERS,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'allowed_pos': ALLOWED_POS,\n",
    "    'custom_stopwords': CUSTOM_STOPWORDS,\n",
    "}\n",
    "\n",
    "config_path = Path(output_full_path) / 'run_configuration.json'\n",
    "\n",
    "if Path(output_full_path).exists():\n",
    "    with open(config_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"Configuration saved to: {config_path}\")\n",
    "    print(\"\\nConfiguration:\")\n",
    "    print(json.dumps(config, indent=2))\n",
    "else:\n",
    "    print(\"Cannot save configuration - output directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### To apply this model to new documents:\n",
    "\n",
    "See the `Apply_Topic_Model.ipynb` notebook (you can create one), or use the command line:\n",
    "\n",
    "```bash\n",
    "python scripts/apply_topic_model.py \\\n",
    "    --model results/topic_modeling_YYYYMMDD/lda_model \\\n",
    "    --dictionary results/topic_modeling_YYYYMMDD/lda_dictionary \\\n",
    "    --input new_documents.csv \\\n",
    "    --output topic_assignments.csv\n",
    "```\n",
    "\n",
    "### To experiment with different parameters:\n",
    "\n",
    "1. Go back to Section 1\n",
    "2. Change NUM_TOPICS, PASSES, or other parameters\n",
    "3. Run all cells again\n",
    "\n",
    "### To process a different dataset:\n",
    "\n",
    "1. Change INPUT_TYPE and related paths in Section 1\n",
    "2. Run all cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}