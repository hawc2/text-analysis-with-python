{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hawc2/Text-Analysis-with-Python/blob/master/notebooks/ocr/BERT_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEFY3olF6P4f"
   },
   "source": [
    "# Resources\n",
    "\n",
    "Tutorial on BERT OCR: \n",
    "\n",
    "https://www.statestitle.com/resource/using-nlp-bert-to-improve-ocr-accuracy/\n",
    "\n",
    "Related: https://medium.com/towards-artificial-intelligence/using-tesseract-ocr-for-text-recognition-with-google-colab-1c4513b9d3e0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWMA-pW63GLb"
   },
   "source": [
    "# Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:26.854634Z",
     "iopub.status.busy": "2026-02-08T02:57:26.854363Z",
     "iopub.status.idle": "2026-02-08T02:57:28.105998Z",
     "shell.execute_reply": "2026-02-08T02:57:28.105528Z"
    },
    "id": "jPWXe_-O3YNU",
    "outputId": "1120a957-b290-4e89-ffe7-2e4b53ae6c1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pytesseract in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (0.3.13)\r\n",
      "Requirement already satisfied: transformers in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (4.57.6)\r\n",
      "Requirement already satisfied: torch in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (2.8.0)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from pytesseract) (25.0)\r\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from pytesseract) (11.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (3.19.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (0.36.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (2026.1.15)\r\n",
      "Requirement already satisfied: requests in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.5)\r\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (0.22.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (0.7.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.3)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.6)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.3)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2025.11.12)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pyenchant in /Users/alexwermer-colan/Library/Python/3.9/lib/python/site-packages (3.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract transformers torch\n",
    "!pip install pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:28.108067Z",
     "iopub.status.busy": "2026-02-08T02:57:28.107918Z",
     "iopub.status.idle": "2026-02-08T02:57:28.111266Z",
     "shell.execute_reply": "2026-02-08T02:57:28.110935Z"
    },
    "id": "mWY0DHX5ejm6",
    "outputId": "77565f5c-d4b2-488b-c5a2-1d241558e381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping apt-get installs; use Homebrew on macOS.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "in_colab = \"google.colab\" in sys.modules or os.environ.get(\"COLAB_RELEASE_TAG\")\n",
    "if in_colab:\n",
    "    !sudo apt-get -y install tesseract-ocr libtesseract-dev\n",
    "    !sudo apt-get -y install libenchant-2-2\n",
    "else:\n",
    "    print(\"Skipping apt-get installs; use Homebrew on macOS.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:28.112706Z",
     "iopub.status.busy": "2026-02-08T02:57:28.112606Z",
     "iopub.status.idle": "2026-02-08T02:57:28.939425Z",
     "shell.execute_reply": "2026-02-08T02:57:28.939134Z"
    },
    "id": "W15cdO8VSSu8",
    "outputId": "da2501d5-095c-4463-f158-e45b1242ce98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexwermer-\n",
      "[nltk_data]     colan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/alexwermer-colan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/alexwermer-colan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/alexwermer-\n",
      "[nltk_data]     colan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:28.940573Z",
     "iopub.status.busy": "2026-02-08T02:57:28.940485Z",
     "iopub.status.idle": "2026-02-08T02:57:32.870593Z",
     "shell.execute_reply": "2026-02-08T02:57:32.870241Z"
    },
    "id": "9zSdCbzf27S1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexwermer-colan/Code/Hawc2/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "from pytesseract import image_to_string\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import re\n",
    "import nltk\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.872171Z",
     "iopub.status.busy": "2026-02-08T02:57:32.872022Z",
     "iopub.status.idle": "2026-02-08T02:57:32.876654Z",
     "shell.execute_reply": "2026-02-08T02:57:32.876438Z"
    },
    "id": "yyDtoUvv-ZK9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyenchant not available: The 'enchant' C library was not found and maybe needs to be installed.\n",
      "See  https://pyenchant.github.io/pyenchant/install.html\n",
      "for details\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this maybe fixed pyenchant install: https://github.com/pyenchant/pyenchant/issues/214\n",
    "try:\n",
    "    import enchant\n",
    "    from enchant.checker import SpellChecker\n",
    "except ImportError as exc:\n",
    "    SpellChecker = None\n",
    "    print(f\"pyenchant not available: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwmNy0x_3Lyp"
   },
   "source": [
    "# File Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.877762Z",
     "iopub.status.busy": "2026-02-08T02:57:32.877691Z",
     "iopub.status.idle": "2026-02-08T02:57:32.879488Z",
     "shell.execute_reply": "2026-02-08T02:57:32.879298Z"
    },
    "id": "ntAIwyTA3mHc",
    "outputId": "8c91573b-9fcb-44df-f40f-3b1c5b6be718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab upload skipped (not in Colab).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    for fn in uploaded.keys():\n",
    "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "            name=fn, length=len(uploaded[fn])))\n",
    "except Exception:\n",
    "    print(\"Colab upload skipped (not in Colab).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.880504Z",
     "iopub.status.busy": "2026-02-08T02:57:32.880432Z",
     "iopub.status.idle": "2026-02-08T02:57:32.895839Z",
     "shell.execute_reply": "2026-02-08T02:57:32.895497Z"
    },
    "id": "yjBRuUA-3FCh",
    "outputId": "7f2c8406-dfab-4f46-e6bc-3478bb79df67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping OCR; Tesseract or file missing: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    }
   ],
   "source": [
    "filename = '19369615323_Page_134.png'\n",
    "try:\n",
    "    _ = pytesseract.get_tesseract_version()\n",
    "    text = image_to_string(Image.open(filename))\n",
    "    text_original = str(text)\n",
    "    print(text_original)\n",
    "except Exception as exc:\n",
    "    print(f\"Skipping OCR; Tesseract or file missing: {exc}\")\n",
    "    text = \"\"\n",
    "    text_original = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gO-FXteY6I7G"
   },
   "source": [
    "# Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.897250Z",
     "iopub.status.busy": "2026-02-08T02:57:32.897131Z",
     "iopub.status.idle": "2026-02-08T02:57:32.899153Z",
     "shell.execute_reply": "2026-02-08T02:57:32.898943Z"
    },
    "id": "7bu4bUru3Nno"
   },
   "outputs": [],
   "source": [
    "# cleanup text\n",
    "rep = { '\\n': ' ', '\\\\': ' ', '\\\"': '\"', '-': ' ', '\"': ' \" ', \n",
    "        '\"': ' \" ', '\"': ' \" ', ',':' , ', '.':' . ', '!':' ! ', \n",
    "        '?':' ? ', \"n't\": \" not\" , \"'ll\": \" will\", '*':' * ', \n",
    "        '(': ' ( ', ')': ' ) ', \"s'\": \"s '\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.900171Z",
     "iopub.status.busy": "2026-02-08T02:57:32.900103Z",
     "iopub.status.idle": "2026-02-08T02:57:32.903522Z",
     "shell.execute_reply": "2026-02-08T02:57:32.903259Z"
    },
    "id": "zaycur3QSEtD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data missing for person extraction; skipping names list.\n"
     ]
    }
   ],
   "source": [
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n",
    "text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n",
    "\n",
    "def get_personslist(text):\n",
    "    personslist = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "            if isinstance(chunk, nltk.tree.Tree) and chunk.label() == 'PERSON':\n",
    "                personslist.insert(0, (chunk.leaves()[0][0]))\n",
    "    return list(set(personslist))\n",
    "\n",
    "try:\n",
    "    personslist = get_personslist(text)\n",
    "except LookupError:\n",
    "    print(\"NLTK data missing for person extraction; skipping names list.\")\n",
    "    personslist = []\n",
    "ignorewords = personslist + [\"!\", \",\", \".\", \"\\\"\", \"?\", '(', ')', '*', \"'\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.904512Z",
     "iopub.status.busy": "2026-02-08T02:57:32.904441Z",
     "iopub.status.idle": "2026-02-08T02:57:32.906731Z",
     "shell.execute_reply": "2026-02-08T02:57:32.906509Z"
    },
    "id": "MV_h990OR_kL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping spellcheck; pyenchant not available.\n"
     ]
    }
   ],
   "source": [
    "# using enchant.checker.SpellChecker, identify incorrect words\n",
    "# maybe replace SpellChecker\n",
    "if SpellChecker is None:\n",
    "    print(\"Skipping spellcheck; pyenchant not available.\")\n",
    "    incorrectwords = []\n",
    "    suggestedwords = []\n",
    "else:\n",
    "    d = SpellChecker(\"en_US\")\n",
    "    words = text.split()\n",
    "\n",
    "    incorrectwords = [w for w in words if not d.check(w) and w not in ignorewords]\n",
    "    # using enchant.checker.SpellChecker, get suggested replacements\n",
    "    suggestedwords = [d.suggest(w) for w in incorrectwords]\n",
    "\n",
    "    # replace incorrect words with [MASK]\n",
    "    for w in incorrectwords:\n",
    "        text = text.replace(w, '[MASK]')\n",
    "        text_original = text_original.replace(w, '[MASK]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.907679Z",
     "iopub.status.busy": "2026-02-08T02:57:32.907619Z",
     "iopub.status.idle": "2026-02-08T02:57:32.909019Z",
     "shell.execute_reply": "2026-02-08T02:57:32.908827Z"
    },
    "id": "oF7fiB96R8nB",
    "outputId": "9d0b8c2c-cc70-455d-f610-5861b4d8cfe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXSMODYO6Ngu"
   },
   "source": [
    "# Load BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.910029Z",
     "iopub.status.busy": "2026-02-08T02:57:32.909956Z",
     "iopub.status.idle": "2026-02-08T02:57:32.912956Z",
     "shell.execute_reply": "2026-02-08T02:57:32.912788Z"
    },
    "id": "aIvda_2n6Kc-",
    "outputId": "a9f8a6d5-0b41-4181-b751-102dba48762f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping BERT predictions; no OCR text available.\n"
     ]
    }
   ],
   "source": [
    "# Load, train and predict using pre-trained model\n",
    "if not text or not text.strip():\n",
    "    print(\"Skipping BERT predictions; no OCR text available.\")\n",
    "    predictions = None\n",
    "    MASKIDS = []\n",
    "else:\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    if not tokenized_text:\n",
    "        print(\"Skipping BERT predictions; tokenizer produced no tokens.\")\n",
    "        predictions = None\n",
    "        MASKIDS = []\n",
    "    else:\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        MASKIDS = [i for i, e in enumerate(tokenized_text) if e == '[MASK]']\n",
    "        # Create the segments tensors\n",
    "        segs = [i for i, e in enumerate(tokenized_text) if e == '.']\n",
    "        segments_ids = []\n",
    "        prev = -1\n",
    "        for k, s in enumerate(segs):\n",
    "            segments_ids = segments_ids + [k] * (s - prev)\n",
    "            prev = s\n",
    "        segments_ids = segments_ids + [len(segs)] * (len(tokenized_text) - len(segments_ids))\n",
    "        if len(segments_ids) != len(tokenized_text):\n",
    "            segments_ids = [0] * len(tokenized_text)\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        # prepare Torch inputs\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        # Load pre-trained model\n",
    "        model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "        model.eval()\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "                predictions = outputs.logits\n",
    "            except Exception as exc:\n",
    "                print(f\"Skipping BERT predictions; {exc}\")\n",
    "                predictions = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ic1XDbikRN8"
   },
   "source": [
    "With Peter's dataset: https://stackoverflow.com/questions/56010551/pytorch-embedding-index-out-of-range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDC089QZ7OBV"
   },
   "source": [
    "# Refine BERT predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T02:57:32.913980Z",
     "iopub.status.busy": "2026-02-08T02:57:32.913925Z",
     "iopub.status.idle": "2026-02-08T02:57:32.916213Z",
     "shell.execute_reply": "2026-02-08T02:57:32.916016Z"
    },
    "id": "R3g7rbnm7NPr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict words for mask using BERT; \n",
    "#refine prediction by matching with proposals from SpellChecker\n",
    "def predict_word(text_original, predictions, maskids):\n",
    "    pred_words=[]\n",
    "    for i in range(len(MASKIDS)):\n",
    "        preds = torch.topk(predictions[0, MASKIDS[i]], k=50) \n",
    "        indices = preds.indices.tolist()\n",
    "        list1 = tokenizer.convert_ids_to_tokens(indices)\n",
    "        list2 = suggestedwords[i]\n",
    "        simmax=0\n",
    "        predicted_token=''\n",
    "        for word1 in list1:\n",
    "            for word2 in list2:\n",
    "                s = SequenceMatcher(None, word1, word2).ratio()\n",
    "                if s is not None and s > simmax:\n",
    "                    simmax = s\n",
    "                    predicted_token = word1\n",
    "        text_original = text_original.replace('[MASK]', predicted_token, 1)\n",
    "    return text_original\n",
    "text_original = predict_word(text_original, predictions, MASKIDS)\n",
    "print (text_original)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOfwH06FwgAGvklT55rM/im",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "BERT OCR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
