{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec30cd70",
   "metadata": {},
   "source": [
    "# BERT-For-Humanists â€” Word Similarity (converted)\n",
    "\n",
    "Converted from `nlp/BERT-For-Humanists_Word-Similarity_English-Public-Domain-Poetry` (original contained long JSON-like plot outputs and code).\n",
    "\n",
    "This notebook contains extracted code snippets and a short provenance note; the raw original was archived before conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf0033",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Source: `nlp/BERT-For-Humanists_Word-Similarity_English-Public-Domain-Poetry`\n",
    "- Content: word similarity visualizations and Word2Vec/embedding utilities (best-effort extraction).\n",
    "- Some large visualization JSON output was omitted and can be recovered from the original file if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted helper: nearest-neighbor helper (from original)\n",
    "def get_nearest(query_vector, n=100):\n",
    "    import numpy as np\n",
    "    cosines = all_word_vectors.dot(query_vector)\n",
    "    ordering = np.flip(np.argsort(cosines))\n",
    "    return ordering[:n]\n",
    "\n",
    "# Example: writing a DataFrame to CSV (seen in original)\n",
    "# df.to_csv('bert-word-ring.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f773d9",
   "metadata": {},
   "source": [
    "## Raw content note\n",
    "The original file contained long Vega/Vega-Lite JSON and cell outputs; to keep the notebook readable I did not inline the full JSON. If you want the raw content preserved inside the repo, I can archive it under `nlp/archive/`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
