{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 2 Topic Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "40KVswYbunE3",
        "f4qStMOwuvYK",
        "MI34VMFq801e"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawc2/Text-Analysis-with-Python/blob/master/Topic_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXOw5gPaRLuQ"
      },
      "source": [
        "# Intro to Topic Modeling with Gensim and pyLDAvis\n",
        "\n",
        "This Colab Notebook guides you through using Python to create an interactive topic modeling visualization. It walks you through the steps of importing data and the necessary packages, cleaning and processing text data, creating a topic model, and visualizing the topics in an interactive, web-based application.\n",
        "\n",
        "\n",
        "If you would like to do more advanced topic modeling, including by integrating Mallet, testing for coherence of the model, visualizing metrics, and examining topic distributions over a set of documents Gensim provides a wide array of resources. I will separately upload a tutorial of advanced topic modeling strategies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxEMrysjRHwB"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsCpHISpQJdT",
        "outputId": "3ad2d546-54e2-4cc0-b1c1-bd5d2959b2ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40KVswYbunE3"
      },
      "source": [
        "# Upload Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1izyiZG8EJ"
      },
      "source": [
        "#from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#for fn in uploaded.keys():\n",
        "#  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xTeWqGwupiP"
      },
      "source": [
        "# Import CSV Data from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVMCzRZYjHyq"
      },
      "source": [
        "RTdata = 'https://raw.githubusercontent.com/hawc2/Text-Analysis-with-Python/master/RottenTomatoes.csv'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEiAMcaMlgvk"
      },
      "source": [
        "#SFdata = 'https://raw.githubusercontent.com/hawc2/Text-Analysis-with-Python/master/Scifi.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlidT20Tu6jj"
      },
      "source": [
        "# Convert RottenTomatoes.csv to Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUM-atjwy0mm"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_dkkdVV3ZjO"
      },
      "source": [
        "df = pd.read_csv(RTdata, usecols=['Username', 'content'], encoding = 'utf-8')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo-GqUxGy_dY"
      },
      "source": [
        "data = df.content.values.tolist()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rxXIUj2e2Xf"
      },
      "source": [
        "### View Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkpYoGOOe0HB"
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EocrECQchTEF"
      },
      "source": [
        "%load_ext google.colab.data_table \n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4qStMOwuvYK"
      },
      "source": [
        "# Convert Scifi.CSV to Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsVmKrOFpB6y"
      },
      "source": [
        "#dfSF = pd.read_csv(SFdata, usecols=['BookChapter', 'text'], encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9zHUakUu4qf"
      },
      "source": [
        "#dfSF['text']=dfSF['text'].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xs0022KpMu_"
      },
      "source": [
        "#dataSF = dfSF.text.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7B4L5MRRFJH"
      },
      "source": [
        "# Clean Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjRgCvQRfOOE"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKiUtIFysZWT"
      },
      "source": [
        "# A simple way to add further stop words\n",
        "#stop_words.append('movie')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7B4DTzZnIJ6"
      },
      "source": [
        "!pip3 install spacy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh0U8nAimp2L"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YO_PUA0uC-F"
      },
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74qiZ1JPjsQh"
      },
      "source": [
        "import re"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXKsWbxrsUg"
      },
      "source": [
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFPfCl6nHHjT"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "      yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9saf7oBhoRdy"
      },
      "source": [
        "print(data_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOtbz8fXfgCt"
      },
      "source": [
        "bigram = gensim.models.Phrases(data_words, min_count=1, threshold=100)\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4qFCAGQfgvA"
      },
      "source": [
        "def remove_stopwords(texts):\n",
        "   return [[word for word in simple_preprocess(str(doc))\n",
        "if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "   return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "#def make_trigrams(texts):\n",
        "#   return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "   texts_out = []\n",
        "   for sent in texts:\n",
        "     doc = nlp(\" \".join(sent))\n",
        "     texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "   return texts_out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRMeqTfHkey6"
      },
      "source": [
        "data_words_nostops = remove_stopwords(data_words)\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=[\n",
        "   'NOUN', 'ADJ', 'VERB', 'ADV'\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctV_0V95kj1p"
      },
      "source": [
        "#print(data_lemmatized[:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JXqo5CI47kE"
      },
      "source": [
        "# Building Dictionary and Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf46pDnu4CNX"
      },
      "source": [
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "texts = data_lemmatized\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EExpaCS7SInJ"
      },
      "source": [
        "# Create Topic Model - Topics 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqbXMdeAHIq5"
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20,\n",
        "                                           random_state=100,\n",
        "                                           update_every=2,\n",
        "                                           chunksize=100,\n",
        "                                           passes=20,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_bC9dfS0q3"
      },
      "source": [
        "# Create Visualization (Save HTML)\n",
        "\n",
        "The easiest way to create the visualization is to reveal it in the Google Colab notebook and save it as an html file that you can view on your browser. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz2SdZiGtzcb"
      },
      "source": [
        "!pip install pyLDAvis\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKhTNneQHJ1C"
      },
      "source": [
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
        "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk7mOcrnktEp"
      },
      "source": [
        "pyLDAvis.save_html(vis, '/content/LDAviz.html')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z83wjLBgsedR"
      },
      "source": [
        "pyLDAvis.display(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH4WlWezsHNy"
      },
      "source": [
        "# Topic Modeling Model - 60 Topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSu3f89PsGtI"
      },
      "source": [
        "lda_model60 = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=60,\n",
        "                                           random_state=100,\n",
        "                                           update_every=2,\n",
        "                                           chunksize=100,\n",
        "                                           passes=20,\n",
        "                                           iterations=200,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7lb7hEasr9u"
      },
      "source": [
        "# Create Visualization (Save HTML)\n",
        "\n",
        "The easiest way to create the visualization is to reveal it in the Google Colab notebook and save it as an html file that you can view on your browser. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lst_Wcwsr-J"
      },
      "source": [
        "vis60 = pyLDAvis.gensim.prepare(lda_model60, corpus, id2word)\n",
        "#vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='mmds')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJBuBBcGsr-Q"
      },
      "source": [
        "pyLDAvis.save_html(vis60, '/content/LDAviz60.html')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LnUVVOJsr-X"
      },
      "source": [
        "pyLDAvis.display(vis60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI34VMFq801e"
      },
      "source": [
        "# Serve Visualization in Browser\n",
        "\n",
        "You can also serve the visualization locally in the browser using the below chunk of code. Beware that caching in your browser and other issues, such as ad-blockers, may require some debugging to get this working on your machine. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn8XNwM58zrM"
      },
      "source": [
        "#pyLDAvis.enable_notebook()\n",
        "#pyLDAvis.show(vis)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}